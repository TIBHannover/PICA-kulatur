#!/usr/bin/env bash
# statt /bin/bash, siehe https://stackoverflow.com/a/16365367/4341322

# stoppe bei Fehlern sofort, siehe
# https://codeinthehole.com/tips/bash-error-reporting/
set -eu -o pipefail

# Trennzeile zwischen PICA-Datensätzen
TRENN_Z='PPN: '

# ermittele deren Anzahl
# https://stackoverflow.com/a/28085361/4341322
# https://stackoverflow.com/a/14093511/4341322
N_TRENN=$(grep -ciE "$TRENN_Z" "$1" | awk '{print $0-2}')
N_STELLEN=$(echo "$N_TRENN" | wc -c | sed -E 's/ //g')

# definiere Dateinamen & lösche vorherige Versionen
ERG="EVTL-makulierbar"
ERG_D="PPN-Exemplare-$1"
ERG_HEAD="PPN,N_Exemplare"
TMP="cache-PICA-Treffer"
TMP1="$ERG_D.tmp1"
TMP2="$ERG_D.tmp2"
ZIP="$1-$ERG"-$(date -u +"%Y%m%d-%H%M").zip
rm -rf "$TMP" "$ERG" "$ERG_D"

# arbeite im temporären Verzeichnis weiter
mkdir "$TMP"

(
cd "$TMP"

# trenne PICA-Download in Einzeldateien auf
csplit \
	-k \
    -f _ \
	-n "$N_STELLEN" \
	../"$1" \
	"/$TRENN_Z/" \
	"{$N_TRENN}" \
	| sort

# ermögliche Schnellprüfung der Aufteilungsanzeige gegen Ergebnisliste
echo "^ ^ ^ Größe (in Byte) der in Einzel-PICA-Datensätze aufgesplitteten $1"
echo " Je größer die Differenz der beiden letzten Zahlen\
 hier drüber ist, desto wahrscheinlicher ist eine zu hohe\
 Exemplaranzahl für die direkt hier drunter folgende PPN."
echo "v v v"

# entferne PICAs ƒ-Delimiter
sed -Ei '' 's|ƒ.| |g' _*

# pro PICA-Datei...
# ...löschen, falls schon als "makuliert", "vermisst", o.ä kommentiert
# (Felder 480… & 237A/8…)
# https://stackoverflow.com/a/4529141/4341322
grep \
	--files-with-matches \
	--ignore-case \
	--extended-regexp \
	"^(480\d|237A/8\d)\s+(Vermi\w+|Makul\w+|Beilage)\s+" \
	./* | xargs rm

# ...extrahiere PPN, zähle Exemplare & schreibe in Ergebnisdatei
# außer, wenn PPN nur 1 Exemplar hat
# 208… & 700… sind Individualsignaturen des Exemplars
for PICA_D in _*; do

	EX_N=$(grep -cE "^(208@/\d{2}|70\d{2})" "$PICA_D")
	if [[ $EX_N == 1 ]]; then
		rm "$PICA_D"
		continue
	fi

	PPN=$(grep -ioE "$TRENN_Z\d+X?" "$PICA_D" | sed -E "s/$TRENN_Z//g")
	mv "$PICA_D" "$PPN-$EX_N.txt"
	echo "$PPN,$EX_N" >> ../"$ERG_D"
done
)

# sortiere Ergebnisdatei nach häufigsten Dubletten
sort \
	--key=2 \
	--field-separator=, \
	--reverse \
	--numeric-sort \
	--output "$ERG_D" \
	"$ERG_D"

# füge CSV-Header hinzu
echo "$ERG_HEAD" > "$TMP1"
cat "$TMP1" "$ERG_D" > "$TMP2"
rm "$TMP1"
mv "$TMP2" "$ERG_D"

# zeige Ergebnisse
sort \
	--key=2 \
	--field-separator=, \
	--numeric-sort \
	"$ERG_D"

echo "
Mit 'open \"$ERG_D\"' kann können diese Ergebnisse auch im Texteditor geöffnet werden."

mv "$TMP" "$ERG"
zip --quiet --recurse-paths "$ZIP" "$ERG"
